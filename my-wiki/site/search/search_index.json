{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> <p>wiki\u8d44\u6e90\u7f51\u7ad9 git@github.com:lianghaoxun/pytorch_for_l_learn.git</p> <p>git config --global user.email \u201c87295223+lianghaoxun@users.noreply.github.com\u201d git config --global user.name \"lianghaoxun\"</p> <p>\u7b2c 1 \u6b65\uff1a\u751f\u6210 SSH \u5bc6\u94a5 ssh-keygen</p>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/","title":"\u4e00\u3001pyTorch \u5de5\u4f5c\u6d41\u7a0b","text":"<p>\u5185\u5bb9</p> <p>1. \u51c6\u5907\u6570\u636e\u5904\u7406\u597d\u6570\u636e\u5fc5\u987b\u662f\u5f20\u91cf\u683c\u5f0f\u6765\u8fdb\u884c\u8bad\u7ec3</p> <p>2. \u5efa\u7acb\u6a21\u578b\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u6765\u5b66\u4e60\u6570\u636e\u4e2d\u7684\u6a21\u5f0f\uff0c\u9009\u62e9\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\u5e76\u6784\u5efa\u8bad\u7ec3\u5faa\u73af\u3002</p> <p>3. \u5c06\u6a21\u578b\u62df\u5408\u5230\u6570\u636e\uff08\u8bad\u7ec3\uff09\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u6570\u636e\u548c\u6a21\u578b\uff0c\u73b0\u5728\u8ba9\u6211\u4eec\u8ba9\u6a21\u578b\uff08\u5c1d\u8bd5\uff09\u5728\uff08\u8bad\u7ec3\uff09\u6570\u636e\u4e2d\u67e5\u627e\u6a21\u5f0f\u3002</p> <p>4. \u8fdb\u884c\u9884\u6d4b\u5e76\u8bc4\u4f30\u6a21\u578b\uff08\u63a8\u7406\uff09\u6211\u4eec\u7684\u6a21\u578b\u5728\u6570\u636e\u4e2d\u53d1\u73b0\u4e86\u6a21\u5f0f\uff0c\u8ba9\u6211\u4eec\u5c06\u5176\u53d1\u73b0\u4e0e\u5b9e\u9645\uff08\u6d4b\u8bd5\uff09\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002</p> <p>5. \u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u60a8\u53ef\u80fd\u60f3\u5728\u5176\u4ed6\u5730\u65b9\u4f7f\u7528\u60a8\u7684\u6a21\u578b\uff0c\u6216\u8005\u7a0d\u540e\u518d\u56de\u6765\u4f7f\u7528\u5b83\uff0c\u6211\u4eec\u5c06\u5728\u6b64\u5904\u4ecb\u7ecd\u8fd9\u4e00\u70b9\u3002</p> <p>6. \u5c06\u6240\u6709\u5185\u5bb9\u653e\u5728\u4e00\u8d77\u8ba9\u6211\u4eec\u5c06\u4ee5\u4e0a\u6240\u6709\u5185\u5bb9\u7ed3\u5408\u8d77\u6765\u3002</p> <p></p>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#_1","title":"\u4e8c\u3001\u5efa\u7acb\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1-pytorch","title":"1. PyTorch \u6a21\u578b\u6784\u5efa\u8981\u70b9","text":"<p>PyTorch \u6709\u56db\u4e2a\uff08\u7ed9\u4e88\u6216\u63a5\u53d7\uff09\u57fa\u672c\u6a21\u5757\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5b83\u6765\u521b\u5efa\u60a8\u53ef\u4ee5\u60f3\u8c61\u7684\u51e0\u4e4e\u4efb\u4f55\u7c7b\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u3002</p> <p>\u5b83\u4eec\u662f<code>torch.nn</code>\u3001<code>torch.optim</code>\u3001<code>torch.utils.data.Dataset</code>\u548c<code>torch.utils.data.DataLoader</code></p> <p>\u4ee5\u4e0b\u901a\u8fc7<code>torch.nn</code>\u6784\u5efa\u7b80\u5355\u7684\u6a21\u578b</p> <ul> <li><code>nn.Module</code>\u5305\u542b\u8f83\u5927\u7684\u6784\u5efa\u5757\uff08\u5c42\uff09</li> <li><code>nn.Parameter</code>\u5305\u542b\u8f83\u5c0f\u7684\u53c2\u6570\uff0c\u4f8b\u5982\u6743\u91cd\u548c\u504f\u5dee\uff08\u5c06\u5b83\u4eec\u653e\u5728\u4e00\u8d77\u6784\u6210<code>nn.Module</code>\uff08s\uff09\uff09</li> <li><code>forward()</code>\u544a\u8bc9\u8f83\u5927\u7684\u5757\u5982\u4f55\u5728 <code>nn.Module</code>\uff08s\uff09\u5185\u5bf9\u8f93\u5165\uff08\u5145\u6ee1\u6570\u636e\u7684\u5f20\u91cf\uff09\u8fdb\u884c\u8ba1\u7b97</li> <li><code>torch.optim</code>\u5305\u542b\u5982\u4f55\u6539\u8fdb\u53c2\u6570\u4ee5<code>nn.Parameter</code>\u66f4\u597d\u5730\u8868\u793a\u8f93\u5165\u6570\u636e\u7684\u4f18\u5316\u65b9\u6cd5</li> </ul>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2y-mx-b","title":"2.\u7ebf\u6027\u56de\u5f52\u6a21\u578b(y = m*x + b)","text":"<pre><code># Create a Linear Regression model class\nclass LinearRegressionModel(nn.Module): # &lt;- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n    def __init__(self):\n        super().__init__() \n        self.weights = nn.Parameter(torch.randn(1, # &lt;- start with random weights (this will get adjusted as the model learns)\n                                                dtype=torch.float), # &lt;- PyTorch loves float32 by default\n                                   requires_grad=True) # &lt;- can we update this value with gradient descent?)\n\n        self.bias = nn.Parameter(torch.randn(1, # &lt;- start with random bias (this will get adjusted as the model learns)\n                                            dtype=torch.float), # &lt;- PyTorch loves float32 by default\n                                requires_grad=True) # &lt;- can we update this value with gradient descent?))\n\n    # Forward defines the computation in the model\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor: # &lt;- \"x\" is the input data (e.g. training/testing features)\n        return self.weights * x + self.bias # &lt;- this is the linear regression formula (y = m*x + b)\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1","title":"\uff081\uff09.\u8f93\u51fa\u6a21\u578b\u7684\u72b6\u6001","text":"<pre><code># Set manual seed since nn.Parameter are randomly initialzied\ntorch.manual_seed(42)\n\n# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\nmodel_0 = LinearRegressionModel()\n\n# Check the nn.Parameter(s) within the nn.Module subclass we created\nlist(model_0.parameters())\n</code></pre> <pre><code># List named parameters \nmodel_0.state_dict()\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2","title":"\uff082\uff09.\u6784\u5efa\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668","text":"<pre><code># Create the loss function\nloss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n\n# Create the optimizer\noptimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))\n\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#3","title":"\uff083\uff09.\u6a21\u578b\u9884\u6d4b","text":"<pre><code># 1. Set the model in evaluation mode\nmodel_0.eval()\n\n# 2. Setup the inference mode context manager\nwith torch.inference_mode():\n  # 3. Make sure the calculations are done with the model and data on the same device\n  # in our case, we haven't setup device-agnostic code yet so our data and model are\n  # on the CPU by default.\n  # model_0.to(device)\n  # X_test = X_test.to(device)\n  y_preds = model_0(X_test)\ny_preds\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#_2","title":"\u4e09\u3001\u8bad\u7ec3\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_1","title":"1.\u8bad\u7ec3\u8fc7\u7a0b","text":"\u6570\u5b57 \u6b65\u9aa4\u540d\u79f0 \u5b83\u6709\u4ec0\u4e48\u4f5c\u7528\uff1f \u4ee3\u7801\u793a\u4f8b 1 \u524d\u4f20 \u8be5\u6a21\u578b\u4e00\u6b21\u904d\u5386\u6240\u6709\u8bad\u7ec3\u6570\u636e\uff0c\u6267\u884c\u5176<code>forward()</code>\u51fd\u6570\u8ba1\u7b97\u3002 <code>model(x_train)</code> 2 \u8ba1\u7b97\u635f\u5931 \u5c06\u6a21\u578b\u7684\u8f93\u51fa\uff08\u9884\u6d4b\uff09\u4e0e\u771f\u5b9e\u60c5\u51b5\u8fdb\u884c\u6bd4\u8f83\u5e76\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u9519\u8bef\u7a0b\u5ea6\u3002 <code>loss = loss_fn(y_pred, y_train)</code> 3 \u96f6\u68af\u5ea6 \u4f18\u5316\u5668\u68af\u5ea6\u8bbe\u7f6e\u4e3a\u96f6\uff08\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f1a\u7d2f\u79ef\uff09\uff0c\u56e0\u6b64\u53ef\u4ee5\u9488\u5bf9\u7279\u5b9a\u8bad\u7ec3\u6b65\u9aa4\u91cd\u65b0\u8ba1\u7b97\u5b83\u4eec\u3002 <code>optimizer.zero_grad()</code> 4 \u5bf9\u635f\u5931\u6267\u884c\u53cd\u5411\u4f20\u64ad \u8ba1\u7b97\u6bcf\u4e2a\u8981\u66f4\u65b0\u7684\u6a21\u578b\u53c2\u6570\u7684\u635f\u5931\u68af\u5ea6\uff08\u6bcf\u4e2a\u53c2\u6570\u5e26\u6709<code>requires_grad=True</code>\uff09\u3002\u8fd9\u79f0\u4e3a\u53cd\u5411\u4f20\u64ad\uff0c\u56e0\u6b64\u662f\u201c\u5411\u540e\u201d\u3002 <code>loss.backward()</code> 5 \u66f4\u65b0\u4f18\u5316\u5668\uff08\u68af\u5ea6\u4e0b\u964d\uff09 \u66f4\u65b0\u5173\u4e8e\u635f\u5931\u68af\u5ea6\u7684\u53c2\u6570<code>requires_grad=True</code>\u4ee5\u6539\u8fdb\u5b83\u4eec\u3002 <code>optimizer.step()</code>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2_1","title":"2.\u6d4b\u8bd5\u8fc7\u7a0b","text":"\u6570\u5b57 \u6b65\u9aa4\u540d\u79f0 \u5b83\u6709\u4ec0\u4e48\u4f5c\u7528\uff1f \u4ee3\u7801\u793a\u4f8b 1 \u524d\u4f20 \u8be5\u6a21\u578b\u4e00\u6b21\u904d\u5386\u6240\u6709\u8bad\u7ec3\u6570\u636e\uff0c\u6267\u884c\u5176<code>forward()</code>\u51fd\u6570\u8ba1\u7b97\u3002 <code>model(x_test)</code> 2 \u8ba1\u7b97\u635f\u5931 \u5c06\u6a21\u578b\u7684\u8f93\u51fa\uff08\u9884\u6d4b\uff09\u4e0e\u771f\u5b9e\u60c5\u51b5\u8fdb\u884c\u6bd4\u8f83\u5e76\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ee5\u4e86\u89e3\u5b83\u4eec\u7684\u9519\u8bef\u7a0b\u5ea6\u3002 <code>loss = loss_fn(y_pred, y_test)</code> 3 \u8ba1\u7b97\u8bc4\u4f30\u6307\u6807\uff08\u53ef\u9009\uff09 \u9664\u4e86\u635f\u5931\u503c\u4e4b\u5916\uff0c\u60a8\u53ef\u80fd\u8fd8\u9700\u8981\u8ba1\u7b97\u5176\u4ed6\u8bc4\u4f30\u6307\u6807\uff0c\u4f8b\u5982\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u6027\u3002 \u81ea\u5b9a\u4e49\u529f\u80fd"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#3_1","title":"3.\u7ebf\u6027\u56de\u5f52\u6848\u4f8b\u8bad\u7ec3\u5b8c\u6574\u8fc7\u7a0b","text":"<pre><code>torch.manual_seed(42)\n\n# Set the number of epochs (how many times the model will pass over the training data)\nepochs = 100\n\n# Create empty loss lists to track values\ntrain_loss_values = []\ntest_loss_values = []\nepoch_count = []\n\nfor epoch in range(epochs):\n    ### Training\n\n    # Put model in training mode (this is the default state of a model)\n    model_0.train()\n\n    # 1. Forward pass on train data using the forward() method inside \n    y_pred = model_0(X_train)\n    # print(y_pred)\n\n    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n    loss = loss_fn(y_pred, y_train)\n\n    # 3. Zero grad of the optimizer\n    optimizer.zero_grad()\n\n    # 4. Loss backwards\n    loss.backward()\n\n    # 5. Progress the optimizer\n    optimizer.step()\n\n    ### Testing\n\n    # Put the model in evaluation mode\n    model_0.eval()\n\n    with torch.inference_mode():\n      # 1. Forward pass on test data\n      test_pred = model_0(X_test)\n\n      # 2. Caculate loss on test data\n      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n\n      # Print out what's happening\n      if epoch % 10 == 0:\n            epoch_count.append(epoch)\n            train_loss_values.append(loss.detach().numpy())\n            test_loss_values.append(test_loss.detach().numpy())\n            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_2","title":"\uff081\uff09\u7ed8\u5236\u8bad\u7ec3\u6d4b\u8bd5\u7684\u635f\u5931\u51fd\u6570\u66f2\u7ebf","text":"<pre><code># Plot the loss curves\nplt.plot(epoch_count, train_loss_values, label=\"Train loss\")\nplt.plot(epoch_count, test_loss_values, label=\"Test loss\")\nplt.title(\"Training and test loss curves\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend();\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#_3","title":"\u56db\u3001\u52a0\u8f7d\u4fdd\u5b58\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_3","title":"1.\u52a0\u8f7d\u6a21\u578b","text":"<pre><code>from pathlib import Path\n\n# 1. Create models directory \nMODEL_PATH = Path(\"models\")\nMODEL_PATH.mkdir(parents=True, exist_ok=True)\n\n# 2. Create model save path \nMODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\nMODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n\n# 3. Save the model state dict \nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n           f=MODEL_SAVE_PATH) \n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2_2","title":"2.\u4fdd\u5b58\u6a21\u578b","text":"<pre><code># Instantiate a new instance of our model (this will be instantiated with random weights)\nloaded_model_0 = LinearRegressionModel()\n\n# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\nloaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#_4","title":"\u4e94\u3001\u6240\u6709\u5185\u5bb9\u6574\u5408","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1pytorch","title":"1.\u5bfc\u5165\u3001pytorch\u3001\u8c03\u7528\u8d44\u6e90","text":"<pre><code># Import PyTorch and matplotlib\nimport torch\nfrom torch import nn # nn contains all of PyTorch's building blocks for neural networks\nimport matplotlib.pyplot as plt\n\n# Check PyTorch version\ntorch.__version__\n</code></pre> <pre><code># Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2model_1","title":"2.\u6a21\u578b\u5f15\u7528\u8d44\u6e90model_1\u4e3a\u4f8b\u5b50","text":"<pre><code># Set model to GPU if it's availalble, otherwise it'll default to CPU\nmodel_1.to(device) # the device variable was set above to be \"cuda\" if available or \"cpu\" if not\nnext(model_1.parameters()).device\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2_3","title":"2.\u6570\u636e\u96c6","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_4","title":"\uff081\uff09\u7ebf\u6027\u56de\u5f52\u6848\u4f8b","text":"<pre><code># Create weight and bias\nweight = 0.7\nbias = 0.3\n\n# Create range values\nstart = 0\nend = 1\nstep = 0.02\n\n# Create X and y (features and labels)\nX = torch.arange(start, end, step).unsqueeze(dim=1) # without unsqueeze, errors will happen later on (shapes within linear layers)\ny = weight * X + bias \n# Split data\ntrain_split = int(0.8 * len(X))\nX_train, y_train = X[:train_split], y[:train_split]\nX_test, y_test = X[train_split:], y[train_split:]\n\nlen(X_train), len(y_train), len(X_test), len(y_test)\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#3_2","title":"3.\u5efa\u7acb\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_5","title":"\uff081\uff09\u6784\u5efa\u635f\u5931\u4f18\u5316\u5668","text":"<pre><code># Create loss function\nloss_fn = nn.L1Loss()\n\n# Create optimizer\noptimizer = torch.optim.SGD(params=model_1.parameters(), # optimize newly created model's parameters\n                            lr=0.01)\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#2_4","title":"\uff082\uff09\u7ebf\u6027\u56de\u5f52\u6848\u4f8b","text":"<pre><code># Subclass nn.Module to make our model\nclass LinearRegressionModelV2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use nn.Linear() for creating the model parameters\n        self.linear_layer = nn.Linear(in_features=1, \n                                      out_features=1)\n\n    # Define the forward computation (input data x flows through nn.Linear())\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.linear_layer(x)\n\n# Set the manual seed when creating the model (this isn't always need but is used for demonstrative purposes, try commenting it out and seeing what happens)\ntorch.manual_seed(42)\nmodel_1 = LinearRegressionModelV2()\nmodel_1, model_1.state_dict()\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#4","title":"4.\u8bad\u7ec3\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_6","title":"\uff081\uff09\u7ebf\u6027\u56de\u5f52\u6848\u4f8b","text":"<pre><code>torch.manual_seed(42)\n\n# Set the number of epochs \nepochs = 1000 \n\n# Put data on the available device\n# Without this, error will happen (not all model/data on device)\nX_train = X_train.to(device)\nX_test = X_test.to(device)\ny_train = y_train.to(device)\ny_test = y_test.to(device)\n\nfor epoch in range(epochs):\n    ### Training\n    model_1.train() # train mode is on by default after construction\n\n    # 1. Forward pass\n    y_pred = model_1(X_train)\n\n    # 2. Calculate loss\n    loss = loss_fn(y_pred, y_train)\n\n    # 3. Zero grad optimizer\n    optimizer.zero_grad()\n\n    # 4. Loss backward\n    loss.backward()\n\n    # 5. Step the optimizer\n    optimizer.step()\n\n    ### Testing\n    model_1.eval() # put the model in evaluation mode for testing (inference)\n    # 1. Forward pass\n    with torch.inference_mode():\n        test_pred = model_1(X_test)\n\n        # 2. Calculate the loss\n        test_loss = loss_fn(test_pred, y_test)\n\n    if epoch % 100 == 0:\n        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#5","title":"5.\u8bc4\u4f30\u6a21\u578b","text":""},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#1_7","title":"\uff081\uff09\u7ebf\u6027\u56de\u5f52\u6848\u4f8b","text":"<p>\u8f93\u51fa\u53c2\u6570</p> <pre><code># Find our model's learned parameters\nfrom pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \nprint(\"The model learned the following values for weights and bias:\")\npprint(model_1.state_dict())\nprint(\"\\nAnd the original values for weights and bias are:\")\nprint(f\"weights: {weight}, bias: {bias}\")\n</code></pre> <p>\u9884\u6d4b</p> <pre><code># Turn model into evaluation mode\nmodel_1.eval()\n\n# Make predictions on the test data\nwith torch.inference_mode():\n    y_preds = model_1(X_test)\ny_preds\n</code></pre> <pre><code>\ndef plot_predictions(train_data=X_train, \n                     train_labels=y_train, \n                     test_data=X_test, \n                     test_labels=y_test, \n                     predictions=None):\n  \"\"\"\n  Plots training data, test data and compares predictions.\n  \"\"\"\n  plt.figure(figsize=(10, 7))\n\n  # Plot training data in blue\n  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n\n  # Plot test data in green\n  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n\n  if predictions is not None:\n    # Plot the predictions in red (predictions were made on the test data)\n    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n\n  # Show the legend\n  plt.legend(prop={\"size\": 14});\n# plot_predictions(predictions=y_preds) # -&gt; won't work... data not on CPU\n\n# Put data on the CPU and plot it\nplot_predictions(predictions=y_preds.cpu())\n</code></pre>"},{"location":"1.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90/#6","title":"6.\u4fdd\u5b58\u52a0\u8f7d\u6a21\u578b","text":"<p>\u4fdd\u5b58</p> <pre><code>from pathlib import Path\n\n# 1. Create models directory \nMODEL_PATH = Path(\"models\")\nMODEL_PATH.mkdir(parents=True, exist_ok=True)\n\n# 2. Create model save path \nMODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\nMODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n\n# 3. Save the model state dict \nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=model_1.state_dict(), # only saving the state_dict() only saves the models learned parameters\n           f=MODEL_SAVE_PATH) \n</code></pre> <p>\u52a0\u8f7d</p> <pre><code># Instantiate a fresh instance of LinearRegressionModelV2\nloaded_model_1 = LinearRegressionModelV2()\n\n# Load model state dict \nloaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n\n# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\nloaded_model_1.to(device)\n\nprint(f\"Loaded model:\\n{loaded_model_1}\")\nprint(f\"Model on device:\\n{next(loaded_model_1.parameters()).device}\")\n</code></pre>"}]}